# Programming-for-Data-Analysis-Assignment

Author: Francesco Troja

This repository serves as a key resource for the first assignment of the **HDip in Computing within ATU University's Data Analytics program**, specifically for the **Programming in Data Analytics** module. It contains a *Jupyter notebook* named `Project.ipynb`, which encapsulates detailed analyses, and supplementary visualizations stored in the plot folder.

## Problem Statement

Create a data set by simulating a real-world phenomenon of your choosing. Then rather than collect data related to the phenomenon, you should model and synthesise such data using Python. We suggest you use the numpy.random package for this purpose. Specifically, in this project, you should:

- Choose a real-world phenomenon that can be measured and for which you could collect at least one hundred data points across at least four different variables.
- Investigate the types of variables involved, their likely distributions, and their relationships with each other.
- Synthesise/simulate a data set as closely matching their properties as possible.
- Detail your research and implement the simulation in a Jupyter notebook - the data set itself can simply be displayed in an output cell within the notebook.

## How to download the Repository

Access the provided link: [Project](https://github.com/C-3sc0/Programming-for-Data-Analysis-Assignment) and select the `<> Code` button. There are two options for accessing the Jupyter Notebook:

- Download it as `ZIP file`;
- clone the repository using the provided `HTTPS link` and integrate it into your local machine.

## Repository's Content

- A file named **README.md** file;
- The [`Project.ipynb`](https://github.com/C-3sc0/Programming-for-Data-Analysis-Assignment/blob/main/Project.ipynb) file, which includes the analysis and simulation of a real-world phenomenon;
- The [`Housing.csv`](https://github.com/C-3sc0/Programming-for-Data-Analysis-Assignment/blob/main/Housing.csv) file containing the data of the Original Dataset;
- A folder labeled [`plots`](https://github.com/C-3sc0/Programming-for-Data-Analysis-Assignment/tree/main/plots) where all graphs or images used during the analysis are stored.

## Technologies Used

The project utilizes **Python 3** as its primary technology stack. To execute the code within the Jupyter Notebook, it's essential to have Python 3 or a higher version installed. The official Python package can be obtained from the [Python website](https://www.python.org/downloads/) for download and installation. The utilization of Python 3 ensures compatibility with an extensive array of libraries and tools.
The libraries employed in the current notebook include:

- Pandas (The documentation can be found in the following link: [Pandas](https://pandas.pydata.org/docs/));
- Matplotlib (The documentation can be found in the following link: [Matplotlib](https://matplotlib.org/stable/index.html));
- Numpy (The documentation can be found in the following link: [Numpy](https://numpy.org/doc/stable/));
- Scipy (The documentation can be found in the following link: [Scipy](https://docs.scipy.org/doc/scipy/));
- Seaborn (The documentation can be found in the following link: [Seaborn](https://seaborn.pydata.org/));
- Fitter (The documentation can be found in the following link: [Fitter](https://fitter.readthedocs.io/en/latest/)).

The majority of the required libraries are typically pre-installed in the Python environment. In cases where a library is not present, the `pip command``, serving as the Python package installer, can be employed. To facilitate the installation process, open the terminal and execute the following command:

```python
pip install library_name
```

It's important to substitute "library_name" with the actual name of the library intended for installation.

## References

In the notebook, references are appropriately cited within the sections where they're utilized and compiled at the end. While some references might not be directly applied in the notebook, they were consulted to enhance comprehension of the related topics covered.
